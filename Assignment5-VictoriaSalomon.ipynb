{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1a38e2c-176a-4fb9-b28e-562c102a6839",
   "metadata": {},
   "source": [
    "## Step 0 — Imports Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "80c1ed87-a62f-4620-9f90-8852f3d00e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce3fdfa1-7667-4255-8996-9ca5a4fee86e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy 2.3.5\n",
      "torch 2.2.2\n",
      "CUDA available: False\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import faiss\n",
    "import pandas as pd\n",
    "\n",
    "print(\"numpy\", np.__version__)\n",
    "print(\"torch\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ac8381e-ceec-4f7a-80a1-44154c329940",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import faiss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3ee6da-acfc-4677-a3d6-899c52cd9b22",
   "metadata": {},
   "source": [
    "## Step 1 — Knowledge Base (KB)\n",
    "\n",
    "Create a small KB for your RAG system."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011fb18a-dca6-4250-aa96-0f5c7a43e58f",
   "metadata": {},
   "source": [
    "kb_text = \"\"\"\n",
    "Company X is committed to environmental sustainability. All employees are encouraged\n",
    "to reduce waste, recycle, and conserve energy. The company hosts an annual\n",
    "sustainability week where departments compete to implement green initiatives.\n",
    "\n",
    "Employees are eligible for remote work up to two days per week. Flexible hours\n",
    "are allowed with manager approval. The HR department maintains a digital leave\n",
    "tracking system and processes requests within 48 hours.\n",
    "\n",
    "The company provides training programs for career growth, including workshops\n",
    "on communication, leadership, and technical skills. Participation is voluntary\n",
    "but recommended for all employees to enhance skill development.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f03be2-700a-4bb6-a4c8-c1c98629549d",
   "metadata": {},
   "source": [
    "## Step 2 - Split it into chunks (useful for embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "906e9ffe-3d9c-4433-8323-7a2c7ae9c7c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunks: ['Company X is committed to environmental sustainability. All employees are encouraged\\nto reduce waste, recycle, and conserve energy. The company hosts an annual\\nsustainability week where departments compete to implement green initiatives.', 'Employees are eligible for remote work up to two days per week. Flexible hours\\nare allowed with manager approval. The HR department maintains a digital leave\\ntracking system and processes requests within 48 hours.', 'The company provides training programs for career growth, including workshops\\non communication, leadership, and technical skills. Participation is voluntary\\nbut recommended for all employees to enhance skill development.']\n"
     ]
    }
   ],
   "source": [
    "kb_chunks = kb_text.strip().split(\"\\n\\n\")\n",
    "print(\"Chunks:\", kb_chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a888de-7ee9-442e-95c2-a87a7bdbd555",
   "metadata": {},
   "source": [
    "## Step 3 — Generate embeddings\n",
    "\n",
    "Use a Sentence Transformer to embed KB chunks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bfe979f2-db79-46e2-9116-3fcea111eb8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1f377da985147b7afcca4a7eb9526d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ff89615579246b69b53095cb9d8fb13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c375f46f2b84f398fc10e7b77167cf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41cd9675be3847089d9ac6fb9aa3d57e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78ce06c93b624dcfb4b28e4bbb9e34a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6978d02a81bd45e38412764b111bb72b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc0e2b96056a43d48da663c7f46a5396",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "994e11d299ca4e48bea311b69007a0aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3faa10a9f3864f2b95993f57794953fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b05b2cd2a82a40d29fcab770dcc5ca27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06615a5240bb40d0b5734fb64c36b0f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KB embeddings shape: torch.Size([3, 384])\n"
     ]
    }
   ],
   "source": [
    "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "kb_embeddings = embedding_model.encode(kb_chunks, convert_to_tensor=True)\n",
    "print(\"KB embeddings shape:\", kb_embeddings.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24dd7f48-9c6a-4ec5-9bd3-46b03855afe2",
   "metadata": {},
   "source": [
    "## Step 4 — Build FAISS index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62380f72-c427-4689-8bed-2fd1e35ee76d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of vectors in FAISS: 3\n"
     ]
    }
   ],
   "source": [
    "d = kb_embeddings.shape[1]  # embedding dimension\n",
    "index = faiss.IndexFlatL2(d)  # L2 distance index\n",
    "index.add(kb_embeddings.cpu().numpy())  # add KB embeddings\n",
    "print(\"Number of vectors in FAISS:\", index.ntotal)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887380bf-cc6c-4364-b923-6af33db4e2f1",
   "metadata": {},
   "source": [
    "## Step 5 — Retrieval function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c9d97d20-31ec-4929-a410-7d23750071be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve(query: str, k: int = 2, threshold: float = 0.5) -> List[str]:\n",
    "    query_emb = embedding_model.encode([query], convert_to_tensor=True).cpu().numpy()\n",
    "    distances, indices = index.search(query_emb, k)\n",
    "    # Convert distances to similarity (for L2, similarity = 1/(1+distance))\n",
    "    similarity = 1 / (1 + distances)\n",
    "    chunks = []\n",
    "    for i, sim in zip(indices[0], similarity[0]):\n",
    "        if sim >= threshold:\n",
    "            chunks.append(kb_chunks[i])\n",
    "    return chunks if chunks else [\"No relevant information found in KB.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c9b0777d-4ad1-4549-90ff-a0e803640a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve(query: str, k: int = 2) -> List[str]:\n",
    "    query_emb = embedding_model.encode([query], convert_to_tensor=True).cpu().numpy()\n",
    "    distances, indices = index.search(query_emb, k)\n",
    "    return [kb_chunks[i] for i in indices[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c90d3741-2665-4bc2-b783-a36336b1135a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved: ['The company provides training programs for career growth, including workshops\\non communication, leadership, and technical skills. Participation is voluntary\\nbut recommended for all employees to enhance skill development.', 'Company X is committed to environmental sustainability. All employees are encouraged\\nto reduce waste, recycle, and conserve energy. The company hosts an annual\\nsustainability week where departments compete to implement green initiatives.']\n"
     ]
    }
   ],
   "source": [
    "# Example retrieval\n",
    "query_example = \"What training programs does the company provide?\"\n",
    "retrieved_chunks = retrieve(query_example)\n",
    "print(\"Retrieved:\", retrieved_chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eedcd8e-4154-42f5-9d5b-8bd5b8c3ed53",
   "metadata": {},
   "source": [
    "## Step 6 — LLM generation\n",
    "\n",
    "Use a small pre-trained model like t5-small for context-aware generation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e13cb00f-639e-4ab6-92e2-76f7f16d8458",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_model_name = \"t5-small\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(llm_model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(llm_model_name)\n",
    "\n",
    "def generate_answer(query: str, context_chunks: List[str], max_length: int = 200):\n",
    "    if not context_chunks or context_chunks[0] == \"No relevant information found in KB.\":\n",
    "        return \"I don't know — the KB has no relevant information.\"\n",
    "    \n",
    "    # Remove duplicates\n",
    "    context = \" \".join(list(dict.fromkeys(context_chunks)))\n",
    "    \n",
    "    # Make prompt explicit for synthesis / reasoning\n",
    "    prompt = (\n",
    "        f\"Based on the following information, provide a detailed answer to the question.\\n\"\n",
    "        f\"Context: {context}\\n\"\n",
    "        f\"Question: {query}\\n\"\n",
    "        f\"Answer in full sentences, combining information from all relevant parts of the context.\"\n",
    "    )\n",
    "    \n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True)\n",
    "    outputs = model.generate(\n",
    "        **inputs, \n",
    "        max_length=max_length, \n",
    "        do_sample=True, \n",
    "        top_p=0.9, \n",
    "        temperature=0.7\n",
    "    )\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452e3982-134a-465a-bf07-f3d1e023ea44",
   "metadata": {},
   "source": [
    "## Step 6 — Test Cases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca5510f-71d4-4e3a-9d8f-075cf018ea0e",
   "metadata": {},
   "source": [
    "### Test Case 1 (Factual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b0fcfc28-fb78-455b-a974-dfa4e15a2e3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: : Employees are eligible for remote work up to two days per week. Flexible hours are allowed with manager approval. The HR department maintains a digital leave tracking system and processes requests within 48 hours.\n"
     ]
    }
   ],
   "source": [
    "q1 = \"How many remote work days are allowed?\"\n",
    "chunks1 = retrieve(q1)\n",
    "print(\"Answer:\", generate_answer(q1, chunks1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb5d5f39-8a7b-4af9-ac83-339b8b6053c1",
   "metadata": {},
   "source": [
    "### Test Case 2 (Foil/General)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3fe99ae5-c26d-4c88-b2d8-de8cdf99fed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: I don't know — the KB has no relevant information.\n"
     ]
    }
   ],
   "source": [
    "q2 = \"Who founded the company?\"\n",
    "chunks2 = retrieve(q2)\n",
    "print(\"Answer:\", generate_answer(q2, chunks2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fec339dc-f988-4e1e-aabd-1b5f8a8b7024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: Context: The company provides training programs for career growth, including workshops on communication, leadership, and technical skills. Participation is voluntary but recommended for all employees to enhance skill development.\n"
     ]
    }
   ],
   "source": [
    "q3 = \"What initiatives are employees encouraged to do and how are they trained?\"\n",
    "chunks3 = retrieve(q3)\n",
    "print(\"Answer:\", generate_answer(q3, chunks3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a5656b-0188-45f7-80bf-7db848f1750a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (hf)",
   "language": "python",
   "name": "hf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
